парсилка

<h3><b>Описание</b></h3>
    <p>1. requester.py . - делает запросы по выбранному урлу и возвращает значение</p>
    <p>2. breed_parser.py - парсит все категории пород с avito .ru/moskva/koshki и возвращает dict</p>
    <p>3. main_parser.py - ходит по страничкам вида avito. ru/moskva/koshki/порода?p=NUM и парсит инфу из блоков объявленией
    сейчас это id объявления, url на основную страничку объявления, url на тамб и породу
    все это записывается в csv(по дефолту cats_avito.csv)
    ходит нежно и аккуратно и медленно</p>
    <div>4. ad_parser.py  - принимает url на объявления из main_parser.py, делает туда реквесты, и записывает полученные данные в 
     формате</div>  
     <div>
  <ul>
        <li>'id'</li>
        <li>'title'</li>
        <li>'title'</li>
        <li>'date'</li>
        <li>'image_url'</li>
        <li>'price'</li>
        <li>'address'</li>
        <li>'desc'</li>
        <li>'breed'</li> 
  </ul>
    </div>
        <div>в csv
        возможно 4к объявлений будет парсится больше одного дня, возможно все данные будут браться из main_parser.py( тогда
    увы description будет обрезан) Очень сильно перепилен сейчас, <b>актуальное и более менее рабочее  лежит в одноименном файле в ветке main_ad_parsing </b></div>
<h3>Установка и использование</h3>
<pre>
<code>
    # зависимости
    pip install -r requirements.txt
    
    # парсинг по всем страничкам категорий, и вытаскивание части информации и записи в дефолтный csv файл(рейтлимиты не очень)
    # поправленное лежит в ветке rate_limit(сохраняет в файл testtest.csv и дергает как можно больше инфы,так как обходить
    # каждое объявление весьма долго, обходит 1 и 2ю страницы каждой категории)
    python main_parser.py 
    
    # Идет по csv файлу полученному в предыдущем пункте, ходит по урлам и парсит оттуда всякое(формат данных обновился
    в предыдущем пнкте, и нужно тут тоже заправть), в 10 минут обходит около 30 строк
    python ad_parser.py -f testtest.csv
  </code>
  </pre>
